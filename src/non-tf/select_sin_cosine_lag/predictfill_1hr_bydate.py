import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import joblib
import os

class CSVSolarPredictor:
    def __init__(self, target_column='current_power'):
        self.target_column = target_column
        self.models = {}
        self.predictions = {}
        self.results = {}
        
    def load_and_prepare_data(self, csv_path, test_size=0.2, random_state=42):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å CSV ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training"""
        print(f"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å: {csv_path}")
        
        # ‡πÇ‡∏´‡∏•‡∏î CSV
        self.df = pd.read_csv(csv_path)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Datetime
        if 'datetime' in self.df.columns:
            self.df['datetime'] = pd.to_datetime(self.df['datetime'])
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
            self.df = self.df.sort_values('datetime')
            print(f"üìÖ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {self.df['datetime'].min()} ‡∏ñ‡∏∂‡∏á {self.df['datetime'].max()}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            self.df['Year'] = self.df['datetime'].dt.year
            self.df['Month'] = self.df['datetime'].dt.month
            self.df['Day'] = self.df['datetime'].dt.day
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö target column
        if self.target_column not in self.df.columns:
            available_cols = [col for col in self.df.columns if self.df[col].dtype in ['int64', 'float64']]
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{self.target_column}'")
            print(f"‚úÖ ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ: {available_cols}")
            return None
        
        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {self.df.shape}")
        print(f"‚úÖ ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {list(self.df.columns)}")
        
        return self.df
    
    def select_features(self, exclude_columns=None):
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å features ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        if exclude_columns is None:
        
            exclude_columns = [
               'datetime', 'Season' , 
            ]
        
        # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô features
        excluded = exclude_columns + [self.target_column]
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà target
        numerical_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
        self.feature_columns = [col for col in numerical_features if col not in excluded]
        
        # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        self.feature_columns = [col for col in self.feature_columns 
                              if self.df[col].isnull().sum() / len(self.df) < 0.5]
        
        print(f"üîß ‡πÉ‡∏ä‡πâ features ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(self.feature_columns)}")
        print("üìã Features ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:", self.feature_columns)
        
        return self.feature_columns
    
    def split_data(self, split_by='random', test_size=0.2, years=None, custom_ranges=None):
        """‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train/test set
        split_by: 'random', 'year', ‡∏´‡∏£‡∏∑‡∏≠ 'custom'
        custom_ranges: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö split_by='custom' ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        """
        X = self.df[self.feature_columns]
        y = self.df[self.target_column]
        
        if split_by == 'year' and years and 'Year' in self.df.columns:
            # ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ
            train_mask = self.df['Year'].isin(years['train'])
            test_mask = self.df['Year'].isin(years['test'])
            
            X_train, X_test = X[train_mask], X[test_mask]
            y_train, y_test = y[train_mask], y[test_mask]
            
            print(f"üìÖ ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ: Train={years['train']}, Test={years['test']}")
            
        elif split_by == 'custom' and custom_ranges and 'datetime' in self.df.columns:
            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
            train_start, train_end = custom_ranges['train']
            test_ranges = custom_ranges['test']
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training data
            train_mask = (self.df['datetime'] >= train_start) & (self.df['datetime'] <= train_end)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö test data (‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡πà‡∏ß‡∏á)
            test_mask = pd.Series(False, index=self.df.index)
            for test_range in test_ranges:
                test_start, test_end = test_range
                range_mask = (self.df['datetime'] >= test_start) & (self.df['datetime'] <= test_end)
                test_mask = test_mask | range_mask
            
            X_train, X_test = X[train_mask], X[test_mask]
            y_train, y_test = y[train_mask], y[test_mask]
            
            print(f"üìÖ ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á:")
            print(f"   Train: {train_start} ‡∏ñ‡∏∂‡∏á {train_end}")
            print(f"   Test: {len(test_ranges)} ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
            for i, (start, end) in enumerate(test_ranges, 1):
                print(f"        {i}. {start} ‡∏ñ‡∏∂‡∏á {end}")
            
        else:
            # ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, shuffle=True
            )
            print("üé≤ ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°")
        
        print(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î Train set: {X_train.shape}")
        print(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î Test set: {X_test.shape}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≠‡πÑ‡∏´‡∏°
        if X_train.shape[0] == 0:
            print("‚ö†Ô∏è  ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: Train set ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤!")
        if X_test.shape[0] == 0:
            print("‚ö†Ô∏è  ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: Test set ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤!")
        
        return X_train, X_test, y_train, y_test
    
    def initialize_models(self):
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ"""
        self.models = {
            'XGBoost': xgb.XGBRegressor(
                n_estimators=500,
                learning_rate=0.1,
                max_depth=8,
                random_state=42,
                n_jobs=-1
            ),
            'LightGBM': lgb.LGBMRegressor(
                n_estimators=500,
                learning_rate=0.1,
                max_depth=8,
                random_state=42,
                n_jobs=-1
            ),
            'RandomForest': RandomForestRegressor(
                n_estimators=200,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        }
    
    def train_and_evaluate(self, X_train, X_test, y_train, y_test):
        """‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        
        self.predictions = {}
        self.results = {}

        for name, model in self.models.items():
            print(f"üìö ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å {name}...")
            
            try:
                # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                model.fit(X_train, y_train)
                
                # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                y_pred = model.predict(X_test)
                self.predictions[name] = y_pred
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)
                
                self.results[name] = {
                    'MAE': mae,
                    'RMSE': rmse,
                    'R2': r2,
                    'model': model
                }
                
                print(f"   ‚úÖ {name}: MAE={mae:.2f}, RMSE={rmse:.2f}, R¬≤={r2:.4f}")
                
            except Exception as e:
                print(f"   ‚ùå {name} ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        
        return self.results

    def plot_comparison(self, y_test, n_samples=200):
        """‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö"""
        if not self.predictions:
            print("‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
            return
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á figure ‡πÅ‡∏•‡∏∞ axes
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. Actual vs Predicted (Scatter Plot)
        sample_idx = np.random.choice(len(y_test), min(n_samples, len(y_test)), replace=False)
        
        colors = ['red', 'blue', 'green']
        markers = ['o', 's', '^']
        
        for i, (name, y_pred) in enumerate(self.predictions.items()):
            axes[0, 0].scatter(
                y_test.iloc[sample_idx], 
                y_pred[sample_idx], 
                alpha=0.6, 
                label=name,
                color=colors[i],
                marker=markers[i],
                s=30
            )
        
        # ‡πÄ‡∏™‡πâ‡∏ô perfect prediction
        min_val = min(y_test.min(), min([y_pred.min() for y_pred in self.predictions.values()]))
        max_val = max(y_test.max(), max([y_pred.max() for y_pred in self.predictions.values()]))
        
        axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, linewidth=2, label='Perfect Prediction')
        axes[0, 0].set_xlabel('Actual Values')
        axes[0, 0].set_ylabel('Predicted Values')
        axes[0, 0].set_title('Actual vs Predicted Values')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Time Series Prediction (Line Plot)
        if n_samples < len(y_test):
            # ‡∏û‡∏•‡πá‡∏≠‡∏ï actual ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            axes[0, 1].plot(
                y_test.values[:n_samples], 
                label='Actual', 
                alpha=0.8, 
                color='black', 
                linewidth=2
            )
            
            # ‡∏û‡∏•‡πá‡∏≠‡∏ï prediction ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
            for i, (name, y_pred) in enumerate(self.predictions.items()):
                axes[0, 1].plot(
                    y_pred[:n_samples], 
                    label=name, 
                    alpha=0.7, 
                    color=colors[i],
                    linewidth=1.5
                )
            
            axes[0, 1].set_xlabel('Time Steps')
            axes[0, 1].set_ylabel('Power Value')
            axes[0, 1].set_title('Time Series Prediction (First {} Samples)'.format(n_samples))
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Model Comparison (Bar Chart)
        model_names = list(self.results.keys())
        mae_values = [self.results[name]['MAE'] for name in model_names]
        rmse_values = [self.results[name]['RMSE'] for name in model_names]
        
        x_pos = np.arange(len(model_names))
        width = 0.35
        
        bars1 = axes[1, 0].bar(x_pos - width/2, mae_values, width, label='MAE', color='skyblue', alpha=0.8)
        bars2 = axes[1, 0].bar(x_pos + width/2, rmse_values, width, label='RMSE', color='lightcoral', alpha=0.8)
        
        axes[1, 0].set_xlabel('Models')
        axes[1, 0].set_ylabel('Error Values')
        axes[1, 0].set_title('Model Comparison (MAE vs RMSE)')
        axes[1, 0].set_xticks(x_pos)
        axes[1, 0].set_xticklabels(model_names)
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3, axis='y')
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô bar
        for bar, value in zip(bars1, mae_values):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mae_values)*0.01, 
                           f'{value:.2f}', ha='center', va='bottom', fontsize=9)
        
        for bar, value in zip(bars2, rmse_values):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(rmse_values)*0.01, 
                           f'{value:.2f}', ha='center', va='bottom', fontsize=9)
        
        # 4. Feature Importance (Horizontal Bar Chart)
        best_model_name = min(self.results.items(), key=lambda x: x[1]['MAE'])[0]
        best_model = self.results[best_model_name]['model']
        
        if hasattr(best_model, 'feature_importances_'):
            feature_imp = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': best_model.feature_importances_
            }).sort_values('importance', ascending=True).tail(10)  # Top 10 features
            
            if len(feature_imp) > 0:
                axes[1, 1].barh(feature_imp['feature'], feature_imp['importance'], color='lightgreen', alpha=0.8)
                axes[1, 1].set_xlabel('Importance Score')
                axes[1, 1].set_title(f'Top 10 Feature Importance - {best_model_name}')
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤ importance ‡∏ö‡∏ô bar
                for i, (_, row) in enumerate(feature_imp.iterrows()):
                    axes[1, 1].text(row['importance'] + max(feature_imp['importance'])*0.01, i, 
                                   f'{row["importance"]:.3f}', va='center', fontsize=9)
            else:
                axes[1, 1].text(0.5, 0.5, 'No feature importance data', 
                               ha='center', va='center', transform=axes[1, 1].transAxes)
                axes[1, 1].set_title('Feature Importance')
        else:
            axes[1, 1].text(0.5, 0.5, 'Feature importance not available', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('Feature Importance')
        
        # ‡∏õ‡∏£‡∏±‡∏ö layout
        plt.tight_layout()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° overall title
        fig.suptitle('Solar Power Prediction Model Comparison', fontsize=16, y=1.02)
        
        plt.show()
        
        # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
        print("\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
        print("-" * 50)
        for name, result in self.results.items():
            print(f"üè∑Ô∏è  {name}:")
            print(f"   MAE:  {result['MAE']:.2f}")
            print(f"   RMSE: {result['RMSE']:.2f}")
            print(f"   R¬≤:   {result['R2']:.4f}")
            print()
    
    def save_models(self, folder_path='src/non-tf/select_sin_cosine_lag/saved_models'):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß"""
        os.makedirs(folder_path, exist_ok=True)
        
        for name, result in self.results.items():
            filename = os.path.join(folder_path, f'{name}_model.pkl')
            joblib.dump(result['model'], filename)
            print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {name} ‡∏ó‡∏µ‡πà: {filename}")
    
    def load_model(self, model_path, model_name):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ"""
        model = joblib.load(model_path)
        self.models[model_name] = model
        print(f"üì• ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return model

# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ
def run_analysis_from_csv(csv_path, target_column='current_power', split_method='year'):
    """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV"""
    print("="*60)
    print("üî¨ Solar Power Prediction from CSV")
    print("="*60)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á predictor
    predictor = CSVSolarPredictor(target_column)
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = predictor.load_and_prepare_data(csv_path)
    if df is None:
        return
    
    # 2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å features
    feature_columns = predictor.select_features()
    
    # 3. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏î‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏ô‡∏∂‡πà‡∏á)
    if split_method == 'random':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°
        X_train, X_test, y_train, y_test = predictor.split_data(split_by='random', test_size=0.2)
        
    elif split_method == 'year':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Year)
        X_train, X_test, y_train, y_test = predictor.split_data(
            split_by='year', 
            years={'train': [2022, 2023, 2024], 'test': [2021]}
        )
        
    elif split_method == 'custom':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
        # Train: 2022-2024 ‡∏ó‡∏∏‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô, Test: 2021 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 6-12 ‡πÅ‡∏•‡∏∞ 2025 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 1-4
        custom_ranges = {
            'train': ('2022-01-01', '2024-12-31'),
            'test': [
                ('2021-06-01', '2021-12-31'),  # 2021 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 6-12
                ('2025-01-01', '2025-04-30')   # 2025 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 1-4
            ]
        }
        X_train, X_test, y_train, y_test = predictor.split_data(
            split_by='custom', 
            custom_ranges=custom_ranges
        )
    
    # 4. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    predictor.initialize_models()
    results = predictor.train_and_evaluate(X_train, X_test, y_train, y_test)
    
    # 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    predictor.plot_comparison(y_test)
    
    # 6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    predictor.save_models()
    
    # 7. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
    for model_name, metrics in results.items():
        print(f"\nüîç ‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
        print(f"üìä MAE: {metrics['MAE']:.2f}")
        print(f"üìä RMSE: {metrics['RMSE']:.2f}")
        print(f"üìä R¬≤: {metrics['R2']:.4f}")
    
    best_model = min(results.items(), key=lambda x: x[1]['MAE'])
    print(f"\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model[0]}")
    print(f"üìä MAE: {best_model[1]['MAE']:.2f}")
    print(f"üìä RMSE: {best_model[1]['RMSE']:.2f}")
    print(f"üìä R¬≤: {best_model[1]['R2']:.4f}")
    
    return predictor, results

# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3 ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
def run_custom_split_analysis(csv_path, target_column='current_power', train_range=None, test_ranges=None):
    """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á"""
    print("="*60)
    print("üî¨ Solar Power Prediction - Custom Split Analysis")
    print("="*60)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
    if train_range is None:
        train_range = ('2022-01-01', '2024-12-31')  # 2022-2024 ‡∏ó‡∏∏‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    
    if test_ranges is None:
        test_ranges = [
            ('2021-11-01', '2021-12-31'),  # 2021 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 6-12
            ('2025-01-01', '2025-04-30')   # 2025 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô 1-4
        ]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á predictor
    predictor = CSVSolarPredictor(target_column)
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = predictor.load_and_prepare_data(csv_path)
    if df is None:
        return
    
    # 2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å features
    feature_columns = predictor.select_features()
    
    # 3. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
    custom_ranges = {
        'train': train_range,
        'test': test_ranges
    }
    
    X_train, X_test, y_train, y_test = predictor.split_data(
        split_by='custom', 
        custom_ranges=custom_ranges
    )
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≠‡πÑ‡∏´‡∏°
    if X_train.shape[0] == 0 or X_test.shape[0] == 0:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
        print("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:")
        print(f"   ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {df['datetime'].min()} ‡∏ñ‡∏∂‡∏á {df['datetime'].max()}")
        return
    
    # 4. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    predictor.initialize_models()
    results = predictor.train_and_evaluate(X_train, X_test, y_train, y_test)
    
    # 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    predictor.plot_comparison(y_test)
    
    # 6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    predictor.save_models()
    
    # 7. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
    for model_name, metrics in results.items():
        print(f"\nüîç ‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
        print(f"üìä MAE: {metrics['MAE']:.2f}")
        print(f"üìä RMSE: {metrics['RMSE']:.2f}")
        print(f"üìä R¬≤: {metrics['R2']:.4f}")
    
    best_model = min(results.items(), key=lambda x: x[1]['MAE'])
    print(f"\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model[0]}")
    print(f"üìä MAE: {best_model[1]['MAE']:.2f}")
    print(f"üìä RMSE: {best_model[1]['RMSE']:.2f}")
    print(f"üìä R¬≤: {best_model[1]['R2']:.4f}")
    
    return predictor, results

# 4. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    csv_file_path = "src/non-tf/select_sin_cosine_lag/processed_data/solar_data_simple_fill.csv"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô path ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    
    print("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print("1. ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°")
    print("2. ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ")
    print("3. ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á (Train 2022-2024, Test 2021‡πÄ‡∏î‡∏∑‡∏≠‡∏ô6-12 + 2025‡πÄ‡∏î‡∏∑‡∏≠‡∏ô1-4)")

    choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ (1/2/3): ").strip()

    if choice == '1':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°
        predictor, results = run_analysis_from_csv(
            csv_path=csv_file_path,
            target_column='current_power',
            split_method='random'
        )
    elif choice == '2':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ
        predictor, results = run_analysis_from_csv(
            csv_path=csv_file_path,
            target_column='current_power',
            split_method='year'
        )
    elif choice == '3':
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á
        predictor, results = run_custom_split_analysis(
            csv_path=csv_file_path,
            target_column='current_power'
        )
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ô‡∏µ‡πâ ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3 ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
        predictor, results = run_custom_split_analysis(
            csv_path=csv_file_path,
            target_column='current_power'
        )